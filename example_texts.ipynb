{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from utils.wordProcess import *\n",
    "from models.moiveRnn import Model\n",
    "from settings import *\n",
    "from adversary.fgsm import Attack_MOVIE\n",
    "from utils.roc_plot import roc_auc\n",
    "from adversary.jsma import jsma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/dict.pkl','rb') as f :\n",
    "    word_dict = pickle.load(f)\n",
    "word_dict_reverse = {v: k for k, v in word_dict.items()}\n",
    "word_length = len(word_dict)\n",
    "# print(word_length)\n",
    "vocabLimit = 50000\n",
    "max_sequence_len = 500\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "\n",
    "model = Model(embedding_dim, hidden_dim,vocabLimit).to(device)\n",
    "criterion_none = nn.CrossEntropyLoss(reduction='none')\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "checkpoint = torch.load(MOIVE_CKPT_ADV_TRAINING)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "best_acc = 0\n",
    "\n",
    "f = open('data/labeledTrainData.tsv').readlines()\n",
    "\n",
    "bim_attack = Attack_MOVIE(model, F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(x, y_true, eps=0.01):\n",
    "    x = Variable(x.to(device), requires_grad=True)\n",
    "    y_true = Variable(y_true.to(device), requires_grad=False)\n",
    "\n",
    "    x_adv = bim_attack.fgsm(x, y_true, False, eps)\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "original sentiment: 1, changed words num: 2\n",
      "original sentence:  touching well directed autobiography of a talented young director producer . a love story with rabin s assassination in the background . worth seeing !\n",
      "adv sentence:       touching well directed autobiography of a talented young director producer . a love story with rabin s assassination in the not . worth from !\n",
      "original criterion loss: -0.00 -- adversarial criterion loss: 0.62\n",
      "--------------------\n",
      "original sentiment: 0, changed words num: 2\n",
      "original sentence:  comment this movie is impossible . is terrible very improbable bad interpretation e direction . not look !\n",
      "adv sentence:       comment this movie is impossible . is terrible very improbable bad but e direction . it look !\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.43\n",
      "--------------------\n",
      "original sentiment: 0, changed words num: 2\n",
      "original sentence:  an unfunny unworthy picture which is an undeserving end to peter sellers career . it is a pity this movie was ever made .\n",
      "adv sentence:       and unfunny unworthy picture which is an undeserving end to peter sellers career . it is a pity this movie you ever made .\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.21\n",
      "--------------------\n",
      "original sentiment: 0, changed words num: 2\n",
      "original sentence:  you d better choose paul verhoeven s even if you have watched it .\n",
      "adv sentence:       movie d better choose paul verhoeven s even if you have the it .\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.08\n",
      "--------------------\n",
      "original sentiment: 1, changed words num: 1\n",
      "original sentence:  i don t know why i like this movie so well but i never get tired of watching it .\n",
      "adv sentence:       i don t know why i like this movie so well but not never get tired of watching it .\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.73\n",
      "--------------------\n",
      "original sentiment: 1, changed words num: 2\n",
      "original sentence:  obviously written for the stage . lightweight but worthwhile . how can you go wrong with ralph richardson olivier and merle oberon .\n",
      "adv sentence:       obviously written for the stage . lightweight but worthwhile . how can you go wrong with ralph richardson olivier and not the .\n",
      "original criterion loss: -0.00 -- adversarial criterion loss: 0.02\n",
      "--------------------\n",
      "original sentiment: 1, changed words num: 2\n",
      "original sentence:  excellent episode movie ala pulp fiction . days suicides . it doesnt get more depressing than this . movie rating music rating\n",
      "adv sentence:       excellent episode movie ala pulp fiction . days suicides . it doesnt get more depressing than this . movie the music from\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.62\n",
      "--------------------\n",
      "original sentiment: 0, changed words num: 1\n",
      "original sentence:  this movie is terrible but it has some good effects .\n",
      "adv sentence:       this movie is terrible but it has some good effects the\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.21\n",
      "--------------------\n",
      "original sentiment: 0, changed words num: 2\n",
      "original sentence:  ming the merciless does a little bardwork and a movie most foul !\n",
      "adv sentence:       ming the merciless does a little all and a movie most the !\n",
      "original criterion loss: 0.00 -- adversarial criterion loss: 0.03\n"
     ]
    }
   ],
   "source": [
    "# sentence examples\n",
    "for idx, lines in enumerate(f):\n",
    "    if idx > 0:\n",
    "        data = lines.split('\\t')[2]\n",
    "        data = normalizeString(data).strip()\n",
    "        input_data = [word_dict[word] for word in data.split(' ')]\n",
    "        if len(input_data) > 25:\n",
    "            continue\n",
    "        if len(input_data) > max_sequence_len:\n",
    "            input_data = input_data[0:max_sequence_len]\n",
    "        input_data = Variable(torch.LongTensor(input_data)).to(device)\n",
    "        target = int(lines.split('\\t')[1])\n",
    "        target_data = Variable(torch.LongTensor([target])).to(device)\n",
    "        \n",
    "        y_pred, embeddings = model(input_data)\n",
    "        _, predicted = y_pred.max(1)\n",
    "        if predicted.eq(target_data).sum().item():\n",
    "            changed, benign_adv, change_words, loss_benign = jsma(input_data.clone(), target_data, model,\n",
    "                                                                  nb_classes=2, max_iter=20)\n",
    "            if changed and change_words < 3:\n",
    "                adv_data_list = [word_dict_reverse[k.item()] for k in benign_adv]\n",
    "                adv_data = ' '.join(adv_data_list)\n",
    "                \n",
    "                _, input_data_embedding = model(input_data)\n",
    "                _, benign_adv_embedding = model(benign_adv)\n",
    "                benign_undercover = FGSM(input_data_embedding, target_data, eps=0.001)\n",
    "                adv_undercover = FGSM(benign_adv_embedding, 1 - target_data, eps=0.001)\n",
    "\n",
    "                benign_outputs, _ = model(benign_undercover, after_embedding=True)\n",
    "                temp1 = criterion_none(benign_outputs, target_data).detach().cpu().numpy()[0]\n",
    "                adv_outputs, _ = model(adv_undercover, after_embedding=True)\n",
    "                temp2 = criterion_none(adv_outputs, 1 - target_data).detach().cpu().numpy()[0]\n",
    "                    \n",
    "                print('-'*20)\n",
    "                print('original sentiment: %d, changed words num: %d' % (target, change_words))\n",
    "                print('original sentence: ',data)\n",
    "                print('adv sentence:      ',adv_data)\n",
    "                print(('original criterion loss: %.2f -- adversarial criterion loss: %.2f') % (temp1, temp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split criterion loss is 0.117575884.\n",
    "normal sentence --> criterion loss <= 0.117575884\n",
    "adversarial sentence --> criterion loss > 0.117575884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
